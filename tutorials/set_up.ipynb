{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up `neuroposelib` For You\n",
    "Joshua Wu\n",
    "\n",
    "Duke University Biomedical Engineering\n",
    "\n",
    "[Timothy Dunn Lab](https://www.tdunnlab.org/)\n",
    "\n",
    "11 June, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To follow this notebook, please download the contents of the [demo dataset](https://duke.box.com/v/demo-mouse-poses) into the `/neuroposelib/tutorials/data/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General information regarding your `neuroposelib` analysis (e.g. file paths and hyperparameters) is contained in a `config.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuroposelib import read\n",
    "\n",
    "analysis_key = \"tutorial\"\n",
    "config = read.config(\"../configs/\" + analysis_key + \".yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core components to keep track of in `neuroposelib` are your metadata, your skeleton, your poses, and your session ids.\n",
    "\n",
    "Let's first load in the poses and session ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose, ids = read.pose_h5(config[\"data_path\"] + \"demo_mouse.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pose` is a NumPy array containing your pose predictions of shape `(# frames, # keypoints, 3 Cartesian coordinates)`.\n",
    "\n",
    "`ids` is an `int` iterable of length, `# frames`, which keeps track of the recording session each frame belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648000, 18, 3)\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(pose.shape)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to set up is your `meta.csv` (called `demo_meta.csv` in this tutorial).\n",
    "\n",
    "Each row of `demo_meta.csv` contains categorial information for a recording session (e.g. animal identity, sex, strain, experimental condition, etc.) and a session id. The specific categories are fully-determined by you, and depends on the behavioral comparisons you'd like to make.\n",
    "\n",
    "Here the `meta` variable exactly recapitulates your `meta.csv` file in a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id AnimalID     Sex       Strain Condition                     Path\n",
      "0   0       A0    Male  Adora2a-Cre  Baseline  ./data/demo_mouse_0.mat\n",
      "1   1       A1  Female  Adora2a-Cre  Baseline  ./data/demo_mouse_1.mat\n"
     ]
    }
   ],
   "source": [
    "meta, meta_by_frame = read.meta(config[\"data_path\"] + \"demo_meta.csv\", id=ids)\n",
    "\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`meta_by_frame` expands `meta` to assign your metadata to each frame of your pose array. It is also a `pandas` DataFrame and has rows equal to the total number of frames in your pose array. This may be useful in situations where you want to associate frame-wise continuous variables to your metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(meta_by_frame.shape[0] == pose.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it is crucial to set up the connectivity of your keypoint representation. The `Connectivity` class in `neuroposelib` contains attributes for joint names and links between joints (i.e. segments). It also allows you to assign colors to the keypoints and segments for later plotting.\n",
    "\n",
    "Follow the example in `configs/skeletons/demo_mouse.yaml` to create your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "connectivity = read.connectivity_config(\n",
    "    path=config[\"skeleton_path\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labels for the joints should be in order corresponding to the indices of your `pose` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Snout', 'EarR', 'EarL', 'SpineF', 'SpineM', 'Tail_base', 'ForepawR', 'WristR', 'ElbowR', 'ForepawL', 'WristL', 'ElbowL', 'HindpawR', 'AnkleR', 'KneeR', 'HindpawL', 'AnkleL', 'KneeL']\n"
     ]
    }
   ],
   "source": [
    "print(connectivity.joint_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you choose to use Euler angle representations for your joints, you can also specify them in the connectivity config file as tuples of joints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  3]\n",
      " [ 0  2  3]\n",
      " [ 0  3  4]\n",
      " [ 1  3  4]\n",
      " [ 2  3  4]\n",
      " [ 3  4  5]\n",
      " [ 1  3  8]\n",
      " [ 2  3  8]\n",
      " [ 0  3  8]\n",
      " [ 3  8  7]\n",
      " [ 8  7  6]\n",
      " [ 1  3 11]\n",
      " [ 2  3 11]\n",
      " [ 0  3 11]\n",
      " [ 3 11 10]\n",
      " [11 10  9]\n",
      " [ 4  5 14]\n",
      " [ 5 14 13]\n",
      " [14 13 12]\n",
      " [ 4  5 17]\n",
      " [ 5 17 16]\n",
      " [17 16 15]\n",
      " [ 0  3  6]\n",
      " [ 0  3  7]\n",
      " [ 0  3  9]\n",
      " [ 0  3 10]\n",
      " [ 4  5 12]\n",
      " [ 4  5 13]\n",
      " [ 4  5 15]\n",
      " [ 4  5 16]]\n"
     ]
    }
   ],
   "source": [
    "print(connectivity.angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `neuroposelib` with [DANNCE](https://github.com/spoonsso/dannce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're generating your 3D poses from DANNCE, loading into `neuroposelib` is straightforward.\n",
    "\n",
    "Given DANNCE output paths to each recording session in the `meta.csv`, we can use `neuroposelib.read.pose_from_meta` to load and merge all recording sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id AnimalID     Sex       Strain Condition                     Path\n",
      "0   0       A0    Male  Adora2a-Cre  Baseline  ./data/demo_mouse_0.mat\n",
      "1   1       A1  Female  Adora2a-Cre  Baseline  ./data/demo_mouse_1.mat\n"
     ]
    }
   ],
   "source": [
    "pose, ids, meta, meta_by_frame = read.pose_from_meta(\n",
    "    path=config[\"data_path\"] + \"demo_meta.csv\",\n",
    "    connectivity=connectivity,\n",
    "    key=\"Path\",\n",
    "    file_type=\"dannce\",\n",
    ")\n",
    "\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648000, 18, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pose.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
